{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":23812,"sourceType":"datasetVersion","datasetId":17810}],"dockerImageVersionId":31154,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"\nimport os\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set_style('whitegrid')\n\nimport tensorflow as tf\nfrom tensorflow.keras import layers, metrics\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout, BatchNormalization\nfrom tensorflow.keras.optimizers import Adamax\nfrom tensorflow.keras.applications import Xception\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom sklearn.utils import class_weight\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix, classification_report","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T14:03:28.492349Z","iopub.execute_input":"2025-11-11T14:03:28.492882Z","iopub.status.idle":"2025-11-11T14:03:44.828388Z","shell.execute_reply.started":"2025-11-11T14:03:28.492852Z","shell.execute_reply":"2025-11-11T14:03:44.827785Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# import tensorflow as tf\n# from tensorflow.keras import layers\n# import numpy as np\n# import pandas as pd\n# import os\nfrom tqdm import tqdm\nfrom tensorflow.keras.preprocessing import image","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T14:03:44.829799Z","iopub.execute_input":"2025-11-11T14:03:44.830249Z","iopub.status.idle":"2025-11-11T14:03:44.839455Z","shell.execute_reply.started":"2025-11-11T14:03:44.830231Z","shell.execute_reply":"2025-11-11T14:03:44.838778Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# import os\n# import numpy as np\n# import pandas as pd\n# import tensorflow as tf\n# from tensorflow.keras.preprocessing import image\n# from tensorflow.keras.applications import Xception\nfrom tensorflow.keras import Sequential, layers, metrics\n# from tensorflow.keras.optimizers import Adamax\n# from tensorflow.keras.callbacks import EarlyStopping\n# from sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\n# import matplotlib.pyplot as plt\n# import seaborn as sns","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T14:03:44.840194Z","iopub.execute_input":"2025-11-11T14:03:44.840390Z","iopub.status.idle":"2025-11-11T14:03:44.855463Z","shell.execute_reply.started":"2025-11-11T14:03:44.840375Z","shell.execute_reply":"2025-11-11T14:03:44.854870Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# import os\n# import numpy as np\n# import pandas as pd\n# import matplotlib.pyplot as plt\n# import seaborn as sns\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img\n# from sklearn.model_selection import train_test_split\n# from tqdm import tqdm\nimport random","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T14:03:44.856121Z","iopub.execute_input":"2025-11-11T14:03:44.856309Z","iopub.status.idle":"2025-11-11T14:03:44.871527Z","shell.execute_reply.started":"2025-11-11T14:03:44.856294Z","shell.execute_reply":"2025-11-11T14:03:44.870960Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import warnings \nwarnings.filterwarnings(\"ignore\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T14:03:44.872137Z","iopub.execute_input":"2025-11-11T14:03:44.872396Z","iopub.status.idle":"2025-11-11T14:03:44.886070Z","shell.execute_reply.started":"2025-11-11T14:03:44.872375Z","shell.execute_reply":"2025-11-11T14:03:44.885516Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Loading Dataset","metadata":{}},{"cell_type":"code","source":"# ===========================\n# Step 1: Load Original Dataset\n# ===========================\nDATA_DIR = '/kaggle/input/chest-xray-pneumonia/chest_xray'\nfolders = ['train', 'val', 'test']\n\nfilepaths = []\nlabels = []\n\nfor folder in folders:\n    folder_path = os.path.join(DATA_DIR, folder)\n    for category in ['NORMAL', 'PNEUMONIA']:\n        cat_path = os.path.join(folder_path, category)\n        for img in os.listdir(cat_path):\n            filepaths.append(os.path.join(cat_path, img))\n            labels.append(category)\n\ndf = pd.DataFrame({'filepath': filepaths, 'label': labels})\nprint(\"Original dataset size:\", len(df))\nprint(df['label'].value_counts())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T14:03:44.886800Z","iopub.execute_input":"2025-11-11T14:03:44.887013Z","iopub.status.idle":"2025-11-11T14:03:45.031828Z","shell.execute_reply.started":"2025-11-11T14:03:44.886997Z","shell.execute_reply":"2025-11-11T14:03:45.031219Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Visualizing origianl class distribution","metadata":{}},{"cell_type":"code","source":"# ===========================\n# Step 2: Visualize Original Class Distribution\n# ===========================\nplt.figure(figsize=(6,4))\nsns.countplot(x='label', data=df, palette='viridis')\nplt.title(\"Original Class Distribution\")\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T14:03:45.033321Z","iopub.execute_input":"2025-11-11T14:03:45.033517Z","iopub.status.idle":"2025-11-11T14:03:45.553834Z","shell.execute_reply.started":"2025-11-11T14:03:45.033502Z","shell.execute_reply":"2025-11-11T14:03:45.553110Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Augementing only the 'NORMAL' Class images","metadata":{}},{"cell_type":"code","source":"\n# ===========================\n# Step 3: Augment Only NORMAL Class\n# ===========================\nnormal_df = df[df['label'] == 'NORMAL']\npneumonia_df = df[df['label'] == 'PNEUMONIA']\n\ntarget_size = 7000\ncurrent_size = len(df)\nimages_needed = target_size - current_size\nprint(f\"Current total: {current_size}, Need to add: {images_needed}\")\n\n# Number of new images to generate from NORMAL class\nnormal_to_add = images_needed\n\ndatagen = ImageDataGenerator(\n    rotation_range=15,\n    width_shift_range=0.1,\n    height_shift_range=0.1,\n    shear_range=0.1,\n    zoom_range=0.1,\n    horizontal_flip=True,\n    fill_mode='nearest'\n)\n\naugmented_images = []\naugmented_labels = []\n\nnormal_images = normal_df['filepath'].values\nrandom.shuffle(normal_images)\n\nfor img_path in tqdm(normal_images[:normal_to_add], desc=\"Augmenting NORMAL class\"):\n    try:\n        img = load_img(img_path, target_size=(256, 256))\n        x = img_to_array(img)\n        x = np.expand_dims(x, axis=0)\n        i = 0\n        for batch in datagen.flow(x, batch_size=1):\n            augmented_images.append(batch[0].astype(np.uint8))\n            augmented_labels.append('NORMAL')\n            i += 1\n            break  # generate only one image per original\n    except Exception as e:\n        print(f\"Error augmenting {img_path}: {e}\")\n\n# Convert augmented data to arrays\naugmented_images = np.array(augmented_images)\naugmented_labels = np.array(augmented_labels)\nprint(\"Augmented new NORMAL images:\", len(augmented_labels))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T14:03:55.767976Z","iopub.execute_input":"2025-11-11T14:03:55.768532Z","iopub.status.idle":"2025-11-11T14:04:36.051080Z","shell.execute_reply.started":"2025-11-11T14:03:55.768498Z","shell.execute_reply":"2025-11-11T14:04:36.050338Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\n# ===========================\n# Step 3: Augment Only NORMAL Class\n# ===========================\nnormal_df = df[df['label'] == 'NORMAL']\npneumonia_df = df[df['label'] == 'PNEUMONIA']\n\ntarget_size = 7000\ncurrent_size = len(df)\nimages_needed = target_size - current_size\nprint(f\"Current total: {current_size}, Need to add: {images_needed}\")\n\n# Number of new images to generate from NORMAL class\nnormal_to_add = images_needed\n\ndatagen = ImageDataGenerator(\n    rotation_range=15,\n    width_shift_range=0.1,\n    height_shift_range=0.1,\n    shear_range=0.1,\n    zoom_range=0.1,\n    horizontal_flip=True,\n    fill_mode='nearest'\n)\n\naugmented_images = []\naugmented_labels = []\n\nnormal_images = normal_df['filepath'].values\nrandom.shuffle(normal_images)\n\nfor img_path in tqdm(normal_images[:normal_to_add], desc=\"Augmenting NORMAL class\"):\n    try:\n        img = load_img(img_path, target_size=(256, 256))\n        x = img_to_array(img)\n        x = np.expand_dims(x, axis=0)\n        i = 0\n        for batch in datagen.flow(x, batch_size=1):\n            augmented_images.append(batch[0].astype(np.uint8))\n            augmented_labels.append('NORMAL')\n            i += 1\n            break  # generate only one image per original\n    except Exception as e:\n        print(f\"Error augmenting {img_path}: {e}\")\n\n# Convert augmented data to arrays\naugmented_images = np.array(augmented_images)\naugmented_labels = np.array(augmented_labels)\nprint(\"Augmented new NORMAL images:\", len(augmented_labels))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T14:05:20.246347Z","iopub.execute_input":"2025-11-11T14:05:20.246618Z","iopub.status.idle":"2025-11-11T14:05:53.587415Z","shell.execute_reply.started":"2025-11-11T14:05:20.246598Z","shell.execute_reply":"2025-11-11T14:05:53.586775Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Combining orignal + augumented dataset for training","metadata":{}},{"cell_type":"code","source":"# ===========================\n# Step 4: Combine Original + Augmented Data\n# ===========================\n# Load original images into arrays\nall_images = []\nall_labels = []\n\nfor idx, row in tqdm(df.iterrows(), total=len(df), desc=\"Loading Original Images\"):\n    img = load_img(row['filepath'], target_size=(256, 256))\n    img = img_to_array(img)\n    all_images.append(img)\n    all_labels.append(row['label'])\n\nall_images = np.array(all_images)\nall_labels = np.array(all_labels)\n\n# Combine both\nfinal_images = np.concatenate((all_images, augmented_images), axis=0)\nfinal_labels = np.concatenate((all_labels, augmented_labels), axis=0)\n\nprint(f\"\\nFinal Dataset Size after augmentation: {len(final_labels)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T14:06:40.196532Z","iopub.execute_input":"2025-11-11T14:06:40.197299Z","iopub.status.idle":"2025-11-11T14:07:53.565295Z","shell.execute_reply.started":"2025-11-11T14:06:40.197276Z","shell.execute_reply":"2025-11-11T14:07:53.564433Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Visualizing new class distribution","metadata":{}},{"cell_type":"code","source":"# ===========================\n# Step 5: Visualize New Class Distribution\n# ===========================\nplt.figure(figsize=(6,4))\nsns.countplot(x=final_labels, palette='coolwarm')\nplt.title(\"Class Distribution After Augmentation\")\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T14:07:53.566570Z","iopub.execute_input":"2025-11-11T14:07:53.566779Z","iopub.status.idle":"2025-11-11T14:07:53.708827Z","shell.execute_reply.started":"2025-11-11T14:07:53.566764Z","shell.execute_reply":"2025-11-11T14:07:53.708082Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Train Test Split (70,15,15)","metadata":{}},{"cell_type":"code","source":"# ===========================\n# Step 6: Train/Val/Test Split (70/15/15)\n# ===========================\nX_train, X_temp, y_train, y_temp = train_test_split(\n    final_images, final_labels, test_size=0.3, stratify=final_labels, random_state=42\n)\n\nX_val, X_test, y_val, y_test = train_test_split(\n    X_temp, y_temp, test_size=0.5, stratify=y_temp, random_state=42\n)\n\nprint(\"Train:\", X_train.shape, len(y_train))\nprint(\"Validation:\", X_val.shape, len(y_val))\nprint(\"Test:\", X_test.shape, len(y_test))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T14:07:53.709455Z","iopub.execute_input":"2025-11-11T14:07:53.709634Z","iopub.status.idle":"2025-11-11T14:07:55.413468Z","shell.execute_reply.started":"2025-11-11T14:07:53.709619Z","shell.execute_reply":"2025-11-11T14:07:55.412668Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ===========================\n# Step 7: Verify New Distribution\n# ===========================\nfig, axs = plt.subplots(1, 3, figsize=(15, 5))\n\nsns.countplot(x=y_train, ax=axs[0], palette='viridis')\naxs[0].set_title(\"Train Distribution\")\n\nsns.countplot(x=y_val, ax=axs[1], palette='coolwarm')\naxs[1].set_title(\"Validation Distribution\")\n\nsns.countplot(x=y_test, ax=axs[2], palette='magma')\naxs[2].set_title(\"Test Distribution\")\n\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T14:07:55.415005Z","iopub.execute_input":"2025-11-11T14:07:55.415290Z","iopub.status.idle":"2025-11-11T14:07:55.828114Z","shell.execute_reply.started":"2025-11-11T14:07:55.415274Z","shell.execute_reply":"2025-11-11T14:07:55.827271Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Normalisation","metadata":{}},{"cell_type":"code","source":"# ===========================\n# Step 8: Normalize Pixel Values (0â€“1)\n# ===========================\nX_train = X_train.astype('float32') / 255.0\nX_val = X_val.astype('float32') / 255.0\nX_test = X_test.astype('float32') / 255.0","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T14:07:55.828952Z","iopub.execute_input":"2025-11-11T14:07:55.829276Z","iopub.status.idle":"2025-11-11T14:07:59.030947Z","shell.execute_reply.started":"2025-11-11T14:07:55.829251Z","shell.execute_reply":"2025-11-11T14:07:59.030160Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Label Encoding","metadata":{}},{"cell_type":"code","source":"# ===========================\n# Step 9: Encode Labels to 0/1\n# ===========================\nle = LabelEncoder()\ny_train_enc = le.fit_transform(y_train)\ny_val_enc = le.transform(y_val)\ny_test_enc = le.transform(y_test)\n\nprint(\"Encoded labels:\", dict(zip(le.classes_, le.transform(le.classes_))))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T14:07:59.031756Z","iopub.execute_input":"2025-11-11T14:07:59.032018Z","iopub.status.idle":"2025-11-11T14:07:59.038517Z","shell.execute_reply.started":"2025-11-11T14:07:59.031993Z","shell.execute_reply":"2025-11-11T14:07:59.037822Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ===========================\n# Step 10: Verify Everything\n# ===========================\nprint(\"\\nFinal Data Shapes:\")\nprint(\"X_train:\", X_train.shape, \"y_train:\", y_train_enc.shape)\nprint(\"X_val:\", X_val.shape, \"y_val:\", y_val_enc.shape)\nprint(\"X_test:\", X_test.shape, \"y_test:\", y_test_enc.shape)\n\nfig, axs = plt.subplots(1, 3, figsize=(15, 5))\nsns.countplot(x=y_train_enc, ax=axs[0], palette='viridis')\naxs[0].set_title(\"Train Distribution\")\nsns.countplot(x=y_val_enc, ax=axs[1], palette='coolwarm')\naxs[1].set_title(\"Validation Distribution\")\nsns.countplot(x=y_test_enc, ax=axs[2], palette='magma')\naxs[2].set_title(\"Test Distribution\")\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-30T16:44:14.207791Z","iopub.execute_input":"2025-10-30T16:44:14.208461Z","iopub.status.idle":"2025-10-30T16:44:14.688375Z","shell.execute_reply.started":"2025-10-30T16:44:14.208436Z","shell.execute_reply":"2025-10-30T16:44:14.687644Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Xception Net","metadata":{}},{"cell_type":"code","source":"# ===========================\n# Step 6: Build Xception Model\n# ===========================\nbase_model = Xception(weights='imagenet', include_top=False, pooling='avg', input_shape=(256, 256, 3))\nbase_model.trainable = False\n\nmodel = Sequential([\n    base_model,\n    layers.BatchNormalization(),\n    layers.Dropout(0.2),\n    layers.Dense(220, activation='relu'),\n    layers.Dropout(0.1),\n    layers.Dense(60, activation='relu'),\n    layers.Dense(1, activation='sigmoid')\n])\n\nmodel.compile(\n    optimizer=Adamax(learning_rate=0.0001),\n    loss='binary_crossentropy',\n    metrics=['accuracy', metrics.Precision(), metrics.Recall(), metrics.AUC()]\n)\n\nmodel.summary()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-30T16:44:27.407828Z","iopub.execute_input":"2025-10-30T16:44:27.408536Z","iopub.status.idle":"2025-10-30T16:44:30.765743Z","shell.execute_reply.started":"2025-10-30T16:44:27.408514Z","shell.execute_reply":"2025-10-30T16:44:30.765005Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ===========================\n# Step 7: Train Model\n# ===========================\nearly_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n\nhistory = model.fit(\n    X_train, y_train_enc,\n    validation_data=(X_val, y_val_enc),\n    epochs=20,\n    batch_size=32,\n    callbacks=[early_stopping],\n    verbose=1\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-30T16:44:48.027352Z","iopub.execute_input":"2025-10-30T16:44:48.028087Z","iopub.status.idle":"2025-10-30T16:51:12.852510Z","shell.execute_reply.started":"2025-10-30T16:44:48.028061Z","shell.execute_reply":"2025-10-30T16:51:12.851867Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ===========================\n# Step 8: Evaluate Model\n# ===========================\ntest_loss, test_acc, test_prec, test_rec, test_auc = model.evaluate(X_test, y_test_enc, verbose=1)\nprint(f\"\\nðŸ“Š Test Accuracy: {test_acc:.4f}\")\nprint(f\"Precision: {test_prec:.4f}\")\nprint(f\"Recall: {test_rec:.4f}\")\nprint(f\"AUC: {test_auc:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-30T16:51:21.188100Z","iopub.execute_input":"2025-10-30T16:51:21.188380Z","iopub.status.idle":"2025-10-30T16:51:24.853027Z","shell.execute_reply.started":"2025-10-30T16:51:21.188359Z","shell.execute_reply":"2025-10-30T16:51:24.852400Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ===========================\n# Step 9: Plot Training Metrics\n# ===========================\nplt.figure(figsize=(14,5))\nplt.subplot(1,2,1)\nplt.plot(history.history['accuracy'], label='Train Accuracy')\nplt.plot(history.history['val_accuracy'], label='Val Accuracy')\nplt.title('Model Accuracy')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.legend()\n\nplt.subplot(1,2,2)\nplt.plot(history.history['loss'], label='Train Loss')\nplt.plot(history.history['val_loss'], label='Val Loss')\nplt.title('Model Loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-30T16:51:26.507872Z","iopub.execute_input":"2025-10-30T16:51:26.520092Z","iopub.status.idle":"2025-10-30T16:51:26.980243Z","shell.execute_reply.started":"2025-10-30T16:51:26.520049Z","shell.execute_reply":"2025-10-30T16:51:26.979459Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# DenseNet121","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.applications import DenseNet121\n\nbase_model = DenseNet121(weights='imagenet', include_top=False, pooling='avg', input_shape=(256, 256, 3))\nbase_model.trainable = False\n\nmodel = Sequential([\n    base_model,\n    layers.BatchNormalization(),\n    layers.Dropout(0.2),\n    layers.Dense(220, activation='relu'),\n    layers.Dropout(0.1),\n    layers.Dense(60, activation='relu'),\n    layers.Dense(1, activation='sigmoid')\n])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-10T09:45:45.741651Z","iopub.execute_input":"2025-11-10T09:45:45.742179Z","iopub.status.idle":"2025-11-10T09:45:50.283188Z","shell.execute_reply.started":"2025-11-10T09:45:45.742151Z","shell.execute_reply":"2025-11-10T09:45:50.282369Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model.compile(\n    optimizer=Adamax(learning_rate=0.0001),\n    loss='binary_crossentropy',\n    metrics=['accuracy', metrics.Precision(), metrics.Recall(), metrics.AUC()]\n)\n\nmodel.summary()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-10T09:46:35.619734Z","iopub.execute_input":"2025-11-10T09:46:35.620037Z","iopub.status.idle":"2025-11-10T09:46:35.667434Z","shell.execute_reply.started":"2025-11-10T09:46:35.620018Z","shell.execute_reply":"2025-11-10T09:46:35.666915Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ===========================\n# Step 7: Train Model\n# ===========================\nearly_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n\nhistory = model.fit(\n    X_train, y_train_enc,\n    validation_data=(X_val, y_val_enc),\n    epochs=20,\n    batch_size=32,\n    callbacks=[early_stopping],\n    verbose=1\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-10T09:46:39.414169Z","iopub.execute_input":"2025-11-10T09:46:39.414440Z","iopub.status.idle":"2025-11-10T09:51:45.567925Z","shell.execute_reply.started":"2025-11-10T09:46:39.414419Z","shell.execute_reply":"2025-11-10T09:51:45.567102Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ===========================\n# Step 8: Evaluate Model\n# ===========================\ntest_loss, test_acc, test_prec, test_rec, test_auc = model.evaluate(X_test, y_test_enc, verbose=1)\nprint(f\"\\nðŸ“Š Test Accuracy: {test_acc:.4f}\")\nprint(f\"Precision: {test_prec:.4f}\")\nprint(f\"Recall: {test_rec:.4f}\")\nprint(f\"AUC: {test_auc:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-10T09:52:40.226632Z","iopub.execute_input":"2025-11-10T09:52:40.227409Z","iopub.status.idle":"2025-11-10T09:52:42.854087Z","shell.execute_reply.started":"2025-11-10T09:52:40.227382Z","shell.execute_reply":"2025-11-10T09:52:42.853409Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ===========================\n# Step 9: Plot Training Metrics\n# ===========================\nplt.figure(figsize=(14,5))\nplt.subplot(1,2,1)\nplt.plot(history.history['accuracy'], label='Train Accuracy')\nplt.plot(history.history['val_accuracy'], label='Val Accuracy')\nplt.title('Model Accuracy')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.legend()\n\nplt.subplot(1,2,2)\nplt.plot(history.history['loss'], label='Train Loss')\nplt.plot(history.history['val_loss'], label='Val Loss')\nplt.title('Model Loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-10T09:52:58.268209Z","iopub.execute_input":"2025-11-10T09:52:58.268988Z","iopub.status.idle":"2025-11-10T09:52:58.745012Z","shell.execute_reply.started":"2025-11-10T09:52:58.268954Z","shell.execute_reply":"2025-11-10T09:52:58.744271Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Resnet50","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.applications import ResNet50\n\nbase_model = ResNet50(weights='imagenet', include_top=False, pooling='avg', input_shape=(256, 256, 3))\nbase_model.trainable = False\n\nmodel = Sequential([\n    base_model,\n    layers.BatchNormalization(),\n    layers.Dropout(0.2),\n    layers.Dense(220, activation='relu'),\n    layers.Dropout(0.1),\n    layers.Dense(60, activation='relu'),\n    layers.Dense(1, activation='sigmoid')\n])\n\nmodel.compile(\n    optimizer=Adamax(learning_rate=0.0001),\n    loss='binary_crossentropy',\n    metrics=['accuracy', metrics.Precision(), metrics.Recall(), metrics.AUC()]\n)\n\nmodel.summary()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T13:51:48.088554Z","iopub.execute_input":"2025-11-11T13:51:48.088827Z","iopub.status.idle":"2025-11-11T13:51:48.169616Z","shell.execute_reply.started":"2025-11-11T13:51:48.088808Z","shell.execute_reply":"2025-11-11T13:51:48.169090Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ===========================\n# Step 7: Train Model\n# ===========================\nearly_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n\nhistory = model.fit(\n    X_train, y_train_enc,\n    validation_data=(X_val, y_val_enc),\n    epochs=20,\n    batch_size=32,\n    callbacks=[early_stopping],\n    verbose=1\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T13:52:25.752396Z","iopub.execute_input":"2025-11-11T13:52:25.752682Z","iopub.status.idle":"2025-11-11T13:56:58.902117Z","shell.execute_reply.started":"2025-11-11T13:52:25.752663Z","shell.execute_reply":"2025-11-11T13:56:58.901393Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ===========================\n# Step 8: Evaluate Model\n# ===========================\ntest_loss, test_acc, test_prec, test_rec, test_auc = model.evaluate(X_test, y_test_enc, verbose=1)\nprint(f\"\\nðŸ“Š Test Accuracy: {test_acc:.4f}\")\nprint(f\"Precision: {test_prec:.4f}\")\nprint(f\"Recall: {test_rec:.4f}\")\nprint(f\"AUC: {test_auc:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T13:57:06.819005Z","iopub.execute_input":"2025-11-11T13:57:06.819680Z","iopub.status.idle":"2025-11-11T13:57:10.093607Z","shell.execute_reply.started":"2025-11-11T13:57:06.819658Z","shell.execute_reply":"2025-11-11T13:57:10.092956Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ===========================\n# Step 9: Plot Training Metrics\n# ===========================\nplt.figure(figsize=(14,5))\nplt.subplot(1,2,1)\nplt.plot(history.history['accuracy'], label='Train Accuracy')\nplt.plot(history.history['val_accuracy'], label='Val Accuracy')\nplt.title('Model Accuracy')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.legend()\n\nplt.subplot(1,2,2)\nplt.plot(history.history['loss'], label='Train Loss')\nplt.plot(history.history['val_loss'], label='Val Loss')\nplt.title('Model Loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T13:57:15.414618Z","iopub.execute_input":"2025-11-11T13:57:15.415250Z","iopub.status.idle":"2025-11-11T13:57:15.842469Z","shell.execute_reply.started":"2025-11-11T13:57:15.415228Z","shell.execute_reply":"2025-11-11T13:57:15.841721Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# InceptionV3","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.applications import InceptionV3\n\nbase_model = InceptionV3(weights='imagenet', include_top=False, pooling='avg', input_shape=(256, 256, 3))\nbase_model.trainable = False\n\nmodel = Sequential([\n    base_model,\n    layers.BatchNormalization(),\n    layers.Dropout(0.2),\n    layers.Dense(220, activation='relu'),\n    layers.Dropout(0.1),\n    layers.Dense(60, activation='relu'),\n    layers.Dense(1, activation='sigmoid')\n])\n\nmodel.compile(\n    optimizer=Adamax(learning_rate=0.0001),\n    loss='binary_crossentropy',\n    metrics=['accuracy', metrics.Precision(), metrics.Recall(), metrics.AUC()]\n)\n\nmodel.summary()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T14:10:40.874673Z","iopub.execute_input":"2025-11-11T14:10:40.875207Z","iopub.status.idle":"2025-11-11T14:10:40.958583Z","shell.execute_reply.started":"2025-11-11T14:10:40.875184Z","shell.execute_reply":"2025-11-11T14:10:40.958011Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ===========================\n# Step 7: Train Model\n# ===========================\nearly_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n\nhistory = model.fit(\n    X_train, y_train_enc,\n    validation_data=(X_val, y_val_enc),\n    epochs=20,\n    batch_size=32,\n    callbacks=[early_stopping],\n    verbose=1\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T14:10:42.866474Z","iopub.execute_input":"2025-11-11T14:10:42.867075Z","iopub.status.idle":"2025-11-11T14:15:14.314083Z","shell.execute_reply.started":"2025-11-11T14:10:42.867051Z","shell.execute_reply":"2025-11-11T14:15:14.313426Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ===========================\n# Step 8: Evaluate Model\n# ===========================\ntest_loss, test_acc, test_prec, test_rec, test_auc = model.evaluate(X_test, y_test_enc, verbose=1)\nprint(f\"\\nðŸ“Š Test Accuracy: {test_acc:.4f}\")\nprint(f\"Precision: {test_prec:.4f}\")\nprint(f\"Recall: {test_rec:.4f}\")\nprint(f\"AUC: {test_auc:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T14:17:02.822483Z","iopub.execute_input":"2025-11-11T14:17:02.823422Z","iopub.status.idle":"2025-11-11T14:17:06.013526Z","shell.execute_reply.started":"2025-11-11T14:17:02.823397Z","shell.execute_reply":"2025-11-11T14:17:06.012869Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ===========================\n# Step 9: Plot Training Metrics\n# ===========================\nplt.figure(figsize=(14,5))\nplt.subplot(1,2,1)\nplt.plot(history.history['accuracy'], label='Train Accuracy')\nplt.plot(history.history['val_accuracy'], label='Val Accuracy')\nplt.title('Model Accuracy')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.legend()\n\nplt.subplot(1,2,2)\nplt.plot(history.history['loss'], label='Train Loss')\nplt.plot(history.history['val_loss'], label='Val Loss')\nplt.title('Model Loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T14:17:08.144734Z","iopub.execute_input":"2025-11-11T14:17:08.145484Z","iopub.status.idle":"2025-11-11T14:17:08.628882Z","shell.execute_reply.started":"2025-11-11T14:17:08.145460Z","shell.execute_reply":"2025-11-11T14:17:08.628143Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}